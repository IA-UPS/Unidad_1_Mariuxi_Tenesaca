---
title: "Informe Dinámico: Resumen capítulo 1,2 (Machine Learning with R)"
format: html
editor: visual
author: "Mariuxi Maribel Tenesaca Yuqui"
---

# Capítulo 1: Introducing Machine Learning

La idea del aprendizaje automático puede ser malinterpretada debido a las representaciones exageradas en la ciencia ficción como que las máquinas aprenden a pensar por sí mismas y se rebelan contra la humanidad. Sin embargo, en la realidad, el aprendizaje automático se enfoca en aplicaciones prácticas y está más relacionado con la tarea de enseñar a una computadora a resolver problemas específicos. Además, el aprendizaje automático proporciona un conjunto de herramientas para transformar datos en conocimiento accionable, en este capítulo se explicarán los conceptos fundamentales que definen y diferencian los enfoques más comunes del aprendizaje automático.

### **Los orígenes del aprendizaje automático**

Desde el nacimiento, estamos inundados de datos que nuestros sentidos procesan y nuestro cerebro convierte en experiencia.

Los primeros registros de bases de datos registraron información del entorno observable, como los patrones de planetas y estrellas, los resultados de experimentos biológicos y los registros de impuestos, enfermedades y poblaciones. Estos registros requieren que las personas primero observen y luego registren las observaciones.

Hoy en día, estas observaciones están cada vez más automatizadas y registradas sistemáticamente en bases de datos informáticas en constante crecimiento.

La invención de los sensores electrónicos contribuyó aún más a la riqueza de los datos registrados. Estos sensores procesan los datos de manera diferente a los humanos, lo que es beneficioso en muchos sentidos, ya que los datos sensoriales sin procesar pueden permanecer objetivos, sin traducirlos al lenguaje humano.

-   Las observaciones de los sensores no tienen un componente subjetivo y no necesariamente reportan la situación real, ya que sus registros pueden diferir dependiendo del tipo de sensor utilizado para medir la misma situación. Por ejemplo, hay una diferencia entre una cámara que toma fotos en blanco y negro y una cámara que toma fotos en color.

Cada aspecto de nuestras vidas se registra a través de bases de datos y sensores. Gobiernos, empresas y particulares registran todo tipo de información, desde la más importante hasta la más básica. Vivimos en la era de los grandes datos (Big Data), donde tenemos una enorme cantidad de datos que pueden ser procesados ​​por máquinas.

Se buscaba una forma sistemática de dar sentido a toda esta información para tomar decisiones informadas. La solución a este problema radica en el aprendizaje automático, que desarrolla algoritmos para transformar los datos en un comportamiento inteligente. Este campo surgió en un entorno donde los volúmenes de datos, los métodos estadísticos y el poder de cómputo se estaban desarrollando rápidamente, lo que permitió ciclos crecientes en la recopilación de datos más grandes e interesantes.

*Diferencia entre aprendizaje automático y minería de datos*.

El aprendizaje automático se enfoca en realizar tareas específicas, mientras que la minería de datos se enfoca en encontrar información valiosa en grandes bases de datos.

-   Ejemplos: El aprendizaje automático se puede usar para enseñar a los robots a conducir, mientras que la minería de datos se puede usar para identificar los tipos de automóviles más seguros.

### **Usos y abusos del aprendizaje automático**

El aprendizaje automático da sentido a datos complejos y tiene amplia aplicación en diferentes campos como:

-    Predecir los resultados de las elecciones

-    Identifique y filtre los mensajes de spam del correo electrónico

-    Prever actividad delictiva

-    Automatice las señales de tráfico de acuerdo con las condiciones de la carretera

-    Producir estimaciones financieras de tormentas y desastres naturales

-    Examinar la rotación de clientes

-    Crea aviones de pilotaje automático y coches de conducción automática.

-    Identificar personas con capacidad para donar

-   Dirigir la publicidad a tipos específicos de consumidores

Los algoritmos de aprendizaje automático toman datos e identifican patrones. En algunos casos, los resultados son tan exitosos que casi parecen llegar alcanzar un estado casi legendario. A pesar de estar familiarizado con los métodos de aprendizaje automático que funcionan detrás de escena, surge la sensación de asombro y preocupación que se genera al notar que los métodos de aprendizaje automático son capaces de conocernos mejor de lo que nosotros mismos lo que hacemos. Es importante considerar las implicaciones éticas que se derivan del uso de estas tecnologías en la extracción de datos.

### **Consideraciones éticas**

El aprendizaje automático es una nueva disciplina que crea incertidumbre sobre las leyes y las normas sociales. Se debe tener cuidado al recopilar y analizar datos para no violar los términos de servicio, los acuerdos de uso de datos, la confianza o la privacidad.

Las leyes comerciales pueden prohibir el uso de datos raciales, étnicos o religiosos. Incluso cuando se excluyen dichos datos, los algoritmos de aprendizaje automático pueden extraer esta información de datos aparentemente inocuos. En tales casos, se debe considerar la posibilidad de excluir por completo los datos identificables.

La privacidad es importante para los clientes y pueden sentirse aprovechados si sus datos se utilizan para fines para los que no han dado su consentimiento. Los requisitos de privacidad varían según los antecedentes, la edad y la ubicación. Es importante considerar las influencias culturales antes de iniciar un proyecto.

### **¿Cómo aprenden las máquinas?**

El aprendizaje automático implica que una máquina utilice la experiencia pasada para mejorar su rendimiento en el futuro. Sin embargo, esta definición no explica cómo estas tecnologías realmente convierten los datos en conocimiento procesable.

El proceso de aprendizaje, ya sea para un humano o una máquina, se puede dividir en tres componentes básicos.

-   Entrada de datos: Utiliza la observación, el almacenamiento de memoria y el recuerdo.

-   Abstracción: Implica la traducción de datos en representaciones más amplias.

-   Generalización: Utiliza datos abstractos para formar una base para la acción.

![Figura 1. Proceso de aprendizaje](images/primera-04.png){fig-align="center" width="489"}

Para una mejor comprensión del proceso de aprendizaje: Los estudiantes pueden volverse ineficientes con la memoria visual mientras se preparan para los exámenes porque el aprendizaje implica más que solo ingresar datos, se requiere comprensión.

El proceso de aprendizaje consta de tres componentes: entrada de datos, abstracción y generalización. Estos componentes están interconectados y estrechamente relacionados. Si bien los humanos realizan este proceso de manera inconsciente, la computadora debe aclarar estos procesos. La ventaja del aprendizaje automático es que el conocimiento adquirido es transparente y puede verificarse para uso futuro.

### **Abstracción y representación del conocimiento**

El proceso de abstracción es esencial para comprender los datos de entrada sin procesar y transformarlos en un formato estructurado para su procesamiento mediante algoritmos de aprendizaje.

El proceso de representación del conocimiento implica que las computadoras transformen la entrada sin procesar en modelos que describen patrones estructurados de datos. Hay varios tipos de modelos, como modelos gráficos, modelos basados ​​en reglas y modelos de redes neuronales. Ejemplos, incluyen:

-   Ecuaciones, diagramas como árboles y gráficos

-   Reglas lógicas if/else

El proceso de ajustar un modelo a un conjunto de datos se llama "entrenamiento" porque este término describe mejor el proceso real que ocurre cuando el modelo se ajusta a los datos. El texto también dice que el aprendizaje requiere un paso adicional para generalizar el conocimiento a datos futuros, y que la capacitación involucra a un maestro humano que impone un modelo de aprendizaje automático a un aprendiz automático. La figura 2 muestra un ejemplo.

![Figura 2. Modelo](images/segunda.png){fig-align="center" width="441"}

Aunque la mayoría de los modelos de aprendizaje automático no conducen al desarrollo de teorías científicas revolucionarias, pueden revelar relaciones importantes entre datos que nunca antes se habían visto. Los ejemplos incluyen el descubrimiento de genes que pueden estar relacionados con la diabetes, la identificación de patrones en transacciones bancarias que pueden indicar actividad fraudulenta y el descubrimiento de combinaciones de rasgos que pueden indicar nuevas enfermedades.

En resumen, los modelos de aprendizaje automático pueden proporcionar nuevos conocimientos sobre los datos y revelar conexiones significativas.

### **Generalización**

El término generalización se refiere al proceso de transformar el conocimiento abstracto en una forma utilizable. Este proceso es difícil de describir y tradicionalmente se considera que busca en toda la colección de patrones que pueden haber sido adquiridos durante el entrenamiento. La generalización implica el importante descubrimiento de reducir ese conjunto a un número manejable, y los algoritmos de aprendizaje automático utilizan heurísticas, o conjeturas fundamentadas, para desglosar más rápidamente conjuntos de conceptos.

Los algoritmos de aprendizaje automático pueden estar sesgados y sacar conclusiones incorrectas debido al uso inadecuado de la heurística. Por ejemplo, un algoritmo que reconoce rostros puede tener problemas con rostros que no coinciden con su modelo y está sesgado contra ciertas características.

![Figura 3. Algoritmo que reconoce rostros](images/tercero.png){fig-align="center" width="446"}

### **Evaluar el éxito del aprendizaje**

El sesgo es un aspecto inevitable del aprendizaje automático debido al proceso de abstracción y generalización. Cada modelo de aprendizaje tiene sus propias debilidades y sesgos, y no existe un modelo universal que pueda superarlos. Por tanto, el éxito de un modelo depende de su capacidad para generalizar los resultados a nuevos datos, aunque los modelos rara vez generalizan perfectamente a todas las sorpresas.

 Una de las razones por las que los modelos de aprendizaje automático no se generalizan perfectamente es el problema del ruido en los datos. Este ruido es causado por variaciones inexplicables en los datos, que pueden ser causados ​​por eventos aleatorios, errores de medición causados ​​por sensores imprecisos, problemas de informes de datos y errores de registro de datos, entre otros. Los intentos de modelar el ruido en los datos pueden llevar a conclusiones incorrectas y a modelos más complejos que no se generalizan bien en casos nuevos.

### **Pasos para aplicar el aprendizaje automático a sus datos**

El proceso de cualquier tarea de aprendizaje automático se puede dividir en cinco pasos manejables.

1.  El primer paso implica la recolección de datos en un formato electrónico adecuado para el análisis.

2.  El segundo paso se centra en la exploración y preparación de los datos, lo que requiere una gran cantidad de intervención humana.

3.  El tercer paso implica entrenar un modelo en los datos

4.  El cuarto paso evalúa el rendimiento del modelo.

5.  Como cada modelo de aprendizaje automático está sesgado, el quinto y último paso implica mejorar el rendimiento del modelo utilizando estrategias más avanzadas, incluyendo la recolección de datos adicionales y realizar trabajo preparatorio adicional.

Después de los pasos de recopilación y preparación de datos, capacitación del modelo, evaluación y mejora del rendimiento, el modelo se puede implementar para la tarea prevista, como proporcionar datos de valoración para pronósticos, pronósticos financieros, automatización de tareas, etc. Los éxitos y errores en la implementación de modelos pueden proporcionar datos adicionales para entrenar la próxima generación de modelos.

### **Elegir un algoritmo de aprendizaje automático**

El proceso de selección de un algoritmo de aprendizaje automático implica hacer coincidir las características de los datos que se van a aprender con los sesgos de los métodos disponibles. La elección del algoritmo depende del tipo de datos a analizar y de la tarea propuesta. Es importante tener en cuenta este proceso al recopilar, investigar y limpiar datos.

#### **Pensando en los datos de entrada**

Los algoritmos de aprendizaje automático requieren datos de entrenamiento en forma de ejemplos y funciones.

-   En el análisis de datos, una "unidad de observación" es la unidad por la cual se mide un evento, que puede ser una transacción, persona, tiempo, región geográfica o medida. También puede ser una combinación de estas categorías, como el seguimiento del año personal de una persona en diferentes momentos.

-   En el aprendizaje automático, las funciones son atributos o características de ejemplos que se pueden usar para aprender un concepto deseado. Los atributos pueden variar de un conjunto de datos a otro y pueden ser palabras en un correo electrónico o datos genómicos de una biopsia.

#### **Pensando en los tipos de algoritmos de aprendizaje automático**

Existen dos tipos de algoritmos de aprendizaje automático: supervisados ​​y no supervisados. Los algoritmos supervisados ​​se usan para construir modelos predictivos, mientras que los algoritmos no supervisados ​​se usan para construir modelos descriptivos. El tipo de algoritmo a utilizar depende de la tarea de aprendizaje a implementar.

-   **Los** **modelos predictivos**: Se utilizan para predecir un valor utilizando otros valores en un conjunto de datos. No necesariamente necesitan predecir eventos futuros y se pueden usar para predecir eventos pasados ​​o eventos en tiempo real, como el control de semáforos durante las horas pico.

-   **Los** **modelos descriptivos:** Se utilizan para resumir datos de formas nuevas e interesantes y no tienen un objetivo de aprendizaje específico que los distinga de los modelos predictivos. Dado que no existe un establecimiento de objetivos, el proceso de formación se denomina aprendizaje no supervisado. Aunque es difícil imaginar las aplicaciones de los modelos descriptivos, a menudo se utilizan en la minería de datos.

#### **Hacer coincidir sus datos con un algoritmo apropiado**

La siguiente tabla muestra los tipos generales de algoritmos de aprendizaje automático, aunque no cubre todos los algoritmos disponibles.

![](images/cuarto.png){fig-align="center" width="376"}

### **Uso de R para el aprendizaje automático**

Muchos algoritmos necesarios para el aprendizaje automático en R no están incluidos en la instalación básica, pero debido a que R es gratuito y de código abierto, la comunidad de expertos ha agregado algoritmos necesarios para el aprendizaje automático en R base.

#### **Instalación y carga de paquetes R**

El paquete RWeka que proporciona acceso a algoritmos de aprendizaje automático en el paquete Weka basado en Java. En el siguiente enlace se otorga más información:

[Weka 3 - Data Mining with Open Source Machine Learning Software in Java (waikato.ac.nz)](https://www.cs.waikato.ac.nz/~ml/weka/)

#### **Instalación de un paquete R**

La forma más directa de instalar un paquete es a través de:

-   *instalar.paquetes()función.*

Para instalar elRWekapaquete, en el símbolo del sistema R simplemente escriba:

-    *\> instalar.paquetes("RWeka")*

R luego se conectará a CRAN y descargará el paquete en el formato correcto para su sistema operativo.

#### **Instalación de un paquete mediante la interfaz de apuntar y hacer clic**

R es una interfaz gráfica de usuario (GUI) para instalar paquetes disponibles en el menú Paquetes en Windows y Mac OS X.

![Figura 5. Instalación de paquetes](images/quinto.png){fig-align="center" width="329"}

El proceso de instalación del paquete RWeka es diferente en Windows y Mac OS X. En Windows, después de seleccionar la ubicación del espejo CRAN, se muestra una lista de paquetes donde debe buscar RWeka y hacer clic en Aceptar para instalar el paquete y sus dependencias en la ubicación predeterminada.

 En Mac OS X, haga clic en "Obtener lista" para cargar una lista de paquetes, busque RWeka (o utilice la función de búsqueda de paquetes), seleccione "Instalar seleccionados" y, opcionalmente, marque la casilla "Instalar seleccionados". dependencias" para instalar dependencias con paquetes.

![Figura 6. Instalación del paquete RWeka en Windows y Mac OS X](images/sexto.png){fig-align="center" width="295"}

### Resumen

**El aprendizaje automático** es una herramienta poderosa que surgió de la intersección de las estadísticas, la ciencia de bases de datos y la informática. Se utiliza para encontrar información procesable en grandes volúmenes de datos, pero se debe tener cuidado para evitar abusos comunes.

**El aprendizaje automático** implica abstraer datos en representaciones estructuradas y generalizar esa estructura en acción, y puede dividirse en tareas específicas como la clasificación y la predicción numérica. R proporciona soporte de aprendizaje automático en forma de paquetes descargables gratuitamente, pero estos deben instalarse antes de su uso.

## **Capítulo 2**

### **Gestión y comprensión de datos**

El proceso de administrar y comprender los datos es una parte crítica y temprana de cualquier proyecto de aprendizaje automático porque cualquier algoritmo es tan bueno como sus datos de entrada. Aunque quizás no sea tan valiosa como la construcción de modelos, la preparación y exploración de datos es muy importante porque en muchos casos los datos de entrada son complejos y desordenados. La mayor parte del esfuerzo que se dedica a un proyecto de aprendizaje automático se dedica a esta fase.

### **Vectores**

Una estructura de datos básica en R es un vector que almacena un conjunto ordenado de elementos del mismo tipo. El aprendizaje automático utiliza varios tipos comunes de vectores, como enteros, números, caracteres y booleanos, y hay dos valores especiales que representan valores faltantes. Comprender y manipular vectores es esencial para la preparación y el análisis de datos en proyectos de aprendizaje automático.

Se pueden crear vectores simples usando:

-   La función de combinación C ().

-   Dar un nombre usando el operador de flecha \<-, que es el operador de asignación de R.

-   Operador de asignación = en muchos otros lenguajes de programación.

Ejemplo: Un conjunto de vectores que contengan datos sobre tres pacientes médicos.

```{r}
subject_name <- c("John Doe", "Jane Doe", "Steve Graves")
temperature <- c(98.1,98.6,101.4)
flu_status <- c(FALSE, FALSE, TRUE)
```

Para obtener la temperatura corporal de la paciente Jane Doe, o el elemento 2 en el vector de temperatura, simplemente escriba:

```{r}
temperature[2]

```

Se puede obtener un rango de valores utilizando el operador de dos puntos.

```{r}
temperature[2:3]
```

Para excluir los datos de temperatura de Jane Doe, escriba:

```{r}
temperature[-2]

```

Para incluir las dos primeras lecturas de temperatura pero excluir la tercera, escriba:

```{r}
temperature[c(TRUE,TRUE,FALSE)]
```

### **Factores**

R proporciona una estructura de datos llamada factores para representar variables nominales en el aprendizaje automático. Los factores son un caso especial de vectores diseñados para este propósito.

El uso de factores en lugar de vectores de caracteres tiene varias ventajas en términos de eficiencia de la memoria y la capacidad de manejar variables categóricas en algoritmos de aprendizaje automático. Los factores almacenan etiquetas de clase solo una vez y algunos algoritmos tienen rutinas especiales para manejar variables categóricas codificadas como factores. Esto asegura que el modelo manejará los datos correctamente.

Para crear un factor a partir de un personaje vector, simplemente aplique el factor()función. Por ejemplo:

```{r}
gender <- factor(c("MASCULINO","FEMENINO","MASCULINO"))
gender
```

Cuando se crean factores, podemos agregar niveles adicionales que pueden no aparecer en los datos.

```{r}
blood<-factor(c("O","AB","A"),levels = c("A","B","AB","O"))
blood
```

Note que cuando definimos sangre factor para los tres pacientes, especificamos un vector adicional de cuatro posibles tipos de sangre usando niveles =declaración. Como resultado, aunque nuestros datos incluyen solo tipos O, AB, y A, los cuatro tipos se almacenan con sangre factor indicado por la salida Niveles: AB AB O. El almacenamiento del nivel adicional permite la posibilidad de agregar datos con el otro tipo de sangre en el futuro.

### **Listas** 

Las listas en R le permiten almacenar diferentes tipos de valores y se usan comúnmente para almacenar diferentes tipos de datos de entrada y salida, así como conjuntos de parámetros de configuración para modelos de aprendizaje automático.

Para ilustrar las listas, considere el conjunto de datos de pacientes médicos. Si quisiéramos mostrar todos los datos de John Doe (sujeto 1), necesitaríamos ingresar cinco comandos R:

```{r}
subject_name[1]
```

```{r}
temperature[1]
```

```{r}
flu_status[1]
```

```{r}
gender[1]
```

```{r}
blood[1]
```

Esto parece mucho trabajo para mostrar los datos médicos de un paciente. La estructura de la lista nos permite agrupar todos los datos de un paciente en un objeto que podemos usar repetidamente. Similar a crear un vector con C(),se crea una lista usando lista()función como se muestra en el siguiente ejemplo:

```{r}
subject1 <- list(fullname = subject_name[1], 
 temperature = temperature[1],
 flu_status = flu_status[1],
 gender = gender[1],
 blood = blood[1])
subject1
```

Imprimir los datos de un paciente ahora es cuestión de escribir un solo comando:

### **Marcos de datos**

Un marco de datos es una estructura de datos importante que se usa en el aprendizaje automático de R, similar a una hoja de cálculo o una base de datos que contiene filas y columnas de datos. Consiste en vectores o listas de factores con el mismo número de valores, por lo que es una combinación de vectores y listas.

Usando los vectores de datos de pacientes que creamos previamente, elmarco de datos()la función los combina en un marco de datos:

```{r}
pt_data <- data.frame(subject_name, temperature, flu_status,
 gender, blood, stringsAsFactors = FALSE)
pt_data

```

En comparación con los vectores, factores y listas unidimensionales, un marco de datos tiene dos dimensiones y, por lo tanto, se muestra en formato de matriz.

La forma más directa de extraer un solo elemento, en este caso un vector o columna de datos, es referirse a él por su nombre. Por ejemplo, para obtener nombre del tema vectorial, tipo.

```{r}
pt_data$subject_name
```

Se puede usar un vector de nombres para extraer varias columnas de un marco de datos:

```{r}
pt_data[c("temperature", "flu_status")]

```

Para extraer el valor de la primera fila y la segunda columna del marco de datos del paciente (el valor de temperatura para John Doe), ingresaría:

```{r}
 pt_data[1, 2]
```

Si desea más de una fila o columna de datos, puede hacerlo especificando vectores para los números de fila y columna que desea.

```{r}
pt_data[c(1,3),c(2,4)]
```

Para extraer todas las filas o columnas, en lugar de enumerarlas todas, simplemente deje en blanco la
parte de la fila o la columna.

```{r}
pt_data[, 1]

```

Para extraer todas las columnas de la primera fila:

```{r}
pt_data[1, ]
```

Y para extraer todo:

```{r}
pt_data[ , ]
```

Se puede acceder a las columnas por nombre en lugar de por posición, y se pueden usar signos negativos para excluir filas o columnas de datos. Por lo tanto, la declaración:

```{r}
pt_data[c(1, 3), c("temperature", "gender")]
```

Es equivalente a:

```{r}
pt_data[-2,c(-1,-3,-5)]
```

### **Matrices y arreglos**

-   La matriz es una estructura de datos que representa una tabla bidimensional, con filas y columnas de datos.

-   Las matrices R pueden contener cualquier tipo de datos, aunque se usan con mayor frecuencia para operaciones matemáticas y, por lo tanto, normalmente almacenan solo datos numéricos.

Para crear una matriz, simplemente suministre un vector de datos matriz()función, junto con un parámetro que especifica el número de filas (fila)o número de columnas (ncol).

```{r}
m <- matrix(c('a', 'b', 'c', 'd'), nrow = 2)
m
```

Esto es equivalente a la matriz producida usando ncol = 2:

```{r}
m <- matrix(c('a', 'b', 'c', 'd'), ncol = 2)
m
```

Con seis valores, solicitar dos filas crea una matriz con tres columnas:

```{r}
m <- matrix(c('a', 'b', 'c', 'd', 'e', 'f'), nrow = 2)
m
```

De manera similar, solicitar dos columnas crea una matriz con tres filas:

```{r}
m <- matrix(c('a', 'b', 'c', 'd', 'e', 'f'), ncol = 2)
m
```

Del mismo modo, se pueden solicitar filas o columnas enteras:

```{r}
m[1, ]
```

```{r}
m[, 1]
```

### **Gestión de datos con R**














